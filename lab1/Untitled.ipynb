{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97784f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_errors(current_w, X, Y):\n",
    "    # This function:\n",
    "    # computes the number of misclassified samples\n",
    "    # returns the index of all misclassified samples\n",
    "    # if there are no misclassified samples, returns -1 as index\n",
    "\n",
    "    predicted_labels = np.sign(X.dot(current_w))\n",
    "    \n",
    "    # Compare the predicted labels with the true labels\n",
    "    errors = predicted_labels != Y\n",
    "    \n",
    "    # Count the number of errors\n",
    "    num_errors = errors.sum()\n",
    "    \n",
    "    # Find the index of the first error\n",
    "    index_error = -1\n",
    "    if num_errors > 0:\n",
    "        index_error = np.where(errors)[0][0]\n",
    "    \n",
    "    return num_errors, index_error\n",
    "    \n",
    "    \n",
    "    \n",
    "def perceptron_update(current_w, x, y):\n",
    "    # Place in this function the update rule of the perceptron algorithm\n",
    "    # Remember that numpy arrays can be treated as generalized variables\n",
    "    # therefore given array a = [1,2,3,4], the operation b = 10*a will yield\n",
    "    # b = [10, 20, 30, 40]\n",
    "    new_w = current_w + x * y\n",
    "    return new_w\n",
    "\n",
    "def perceptron_no_randomization(X, Y, max_num_iterations):\n",
    "    \n",
    "    # Initialize some support variables\n",
    "    num_samples = X.shape[0]\n",
    "    # best_errors will keep track of the best (minimum) number of errors\n",
    "    # seen throughout training, used for the update of the best_w variable\n",
    "    best_error = num_samples + 1\n",
    "    \n",
    "    # Initialize the weights of the algorith with w=0\n",
    "    curr_w = np.zeros(X.shape[1])\n",
    "    # The best_w variable will be used to keep track of the best solution\n",
    "    best_w = curr_w.copy()\n",
    "\n",
    "    # compute the number of misclassified samples and the index of the first of them\n",
    "    num_misclassified, index_misclassified = count_errors(curr_w, X, Y)\n",
    "    # update the 'best' variables\n",
    "    if num_misclassified < best_error:\n",
    "        best_error = num_misclassified\n",
    "        best_w = curr_w.copy()\n",
    "    \n",
    "    # initialize the number of iterations\n",
    "    num_iter = 0\n",
    "    # Main loop continue until all samples correctly classified or max # iterations reached\n",
    "    # Remember that to signify that no errors were found we set index_misclassified = -1\n",
    "    while index_misclassified != -1 and num_iter < max_num_iterations:\n",
    "        # Choose the misclassified sample with the lowest index at each iteration\n",
    "        num_iter += 1\n",
    "        x = X[index_misclassified]\n",
    "        y = Y[index_misclassified]\n",
    "        # Update the weights using the perceptron_update function\n",
    "        curr_w = perceptron_update(curr_w, x, y)\n",
    "\n",
    "        # compute the number of misclassified samples and the index of the first of them\n",
    "        num_misclassified, index_misclassified = count_errors(curr_w, X, Y)\n",
    "        # update the 'best' variables\n",
    "        if num_misclassified < best_error:\n",
    "            best_error = num_misclassified\n",
    "            best_w = curr_w.copy()\n",
    "\n",
    "    # as required, return the best error as a ratio with respect to the total number of samples\n",
    "    best_error = best_error / num_samples\n",
    "    return best_w, best_error"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
